## Week 1 Summary (MM/DD/YYYY)

### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 2 Summary (MM/DD/YYYY)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 3 Summary (MM/DD/YYYY)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 4 Summary (09/22/2025)
### This week I worked on:

Deciding the topic for my project and beginning research (watching video's, looking at code playback) for the project

### This week I learned:

It can be hard to come up with a project idea that is resonable! Specifically regarding my project, the back propogation - especially the Multivariable Calculus idea of reducing the error across all the dimension - is something I had not previously known too well regarding Neural Networks.

### My successes this week were:

First, I was able to finish the videos and go over the code playback in it's entirety! Additionally, learning more about the subject itself, the back propogation, error formulas, adjusting towards the lowest error are just a few of the things I was able to learn and better understand about the subject, which will help greatly in understanding how I can use this in conjunction with Q-learning. I was also able to fully implement the code playback by writing it out entirely from the playback, which is a nice bonus.

### The challenges I faced this week were:

The biggest challenges was, first and foremost, coming up with the idea itself. Picking an idea that has enough data to support it (regarding how Machine learning trains), yet keeping the project from being too simple was a delicate balance, one I found a solution to in an interesting way, with the help of Professor Mahoney. Another challenge is just trying to completely and fully understand all the code behind a Neural Network. While I do understand a lot of the material, including the mathematics behind it, a lot of my understanding is conseptual, and writing out a N.N., while not completely neccesary, is something I don't think I am capable of doing yet.

---

## Week 5 Summary (09/29/2025)
### This week I worked on:

Writing down diagrams of the Neural Network from the Code Playback, and also watching some video's on how Q-learning works.

### This week I learned:

Q-learning has a lot more aspects to it than I had first thought. 

### My successes this week were:

Fully implementing a graphical view of the Neural Network, with private variables and functions with their descriptions. I think this has really helped me understand to entire structure of the Neural Network. 

### The challenges I faced this week were:

Trying to understand Q-learning. While I get some of the aspects of it such as the state/action table, and the reward adjusting, a lot of it does fly over my head. I am hoping to really iron out some of the fuzzier details on it soon.

---

## Week 6 Summary (10/06/2025)
### This week I worked on:

Setting up my coding environment on VSCode

### This week I learned:

Nothing too much, I was pretty busy this week with my job and other classes unfortunatly.

### My successes this week were:

Starting to create the structure of my project in my code.

### The challenges I faced this week were:

Just trying to find some tme to work on the project/research more on the topic of Q-learning.

---

## Week 7 Summary (10/13/2025)
### This week I worked on:

Beginning to code my Q-algorithm/Q-table in my project, as well as try to connect the alogrithm to inputs of a TicTacToeBoard, and decide what the outputs for the board/Q-table rewards should look like.

### This week I learned:

How a Q-algorithm looks in a programming language, and how to include things such as the epsilon greedy policy, how to identify actions/states regarding my Q-table, and how TicTacToe can be related to Q-learning.

### My successes this week were:

Setting up a majority of my algorithm, as well as better understanding the TicTacToeBoard class I will use for this assignment. I got a lot more work done on my project than I thought I would have by the end of the week, and my assingment for the TicTacToeBoard class gives me a better understanding on how to connect the two aspects of my project together.

### The challenges I faced this week were:

Understanding how my states should be laid out and deciding how the Agent should be trained. I am not sure what would be acceptable/possible for the state dimension of my Q-table - if I should generate every single board combination, if I should make the marks seperate or just count a space as "taken", and more. As for the training, I believe it would be too inefficient to train against a human, but I also do not know if training against another agent or a program that randomly picks spots is good enough for training. 

---

## Week 8 Summary (10/20/2025)
### This week I worked on:

Implementing a play game function, importing in the TicTacToeBoard class, implementing non-repeatable actions, and worked on the Q-algorithm and Q-table classes.

### This week I learned:

How to properly implement non-repeatabe action with a Q-learning algorithm. It was not fully complete by the end of this week, and there were some bugs, but I learned a lot more about how to properly incorporate this element of TicTacToe in my project.

### My successes this week were:

Properly implementing the game function into the program was the biggest success this week, as well as figuring out how to properly have files added to the github repo show up on my IDE (something I have had trouble with personally). 

### The challenges I faced this week were:

My biggest challenges were implementing the non-repeatable actions. This was something I still had problems with in the next week, and just trying to think out how to connect this with Q-learning was a challenge, but was doable.

---

## Week 9 Summary (10/27/2025)
### This week I worked on:

Getting a primitive print function for the Q-table, and getting the training function for the program "finished". I also reworked some of the data from the Q-table class and finished the state generation for the Q-table. 

### This week I learned:

How to properly format the Q-table data for our Q-algorithm, including the generation of our states, and how it's set up for our rewards table.

### My successes this week were:

Implementing a basic Q-learning function that generates a proper rewards table. With this being the big part of my project, having the algorithm produce an output for our rewards table is a big step in my project. I also succeeded in the fact that my reworks to my Q-table 

### The challenges I faced this week were:

Figuring out just how to implement in the training function was a lot more challenging than I first thought. It required a lot of reworking to my already existing functions/classes, and lots of debugging in areas I was not exactly sure where the problems laid. I still have some work to do on it too, such as tuning the parameters so that the rewards aren't crazily high or low values.

---

## Week 10 Summary (11/03/2025)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 11 Summary (MM/DD/YYYY)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 12 Summary (MM/DD/YYYY)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---

## Week 13 Summary (MM/DD/YYYY)
### This week I worked on:

[Your answer here]

### This week I learned:

[Your answer here]

### My successes this week were:

[Your answer here]

### The challenges I faced this week were:

[Your answer here]

---
